{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3679bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que calcula el IV\n",
    "def calcularIV(var_categoricas,var_target,datos):\n",
    "    import numpy as np\n",
    "    resultado=[] #Array resultado\n",
    "    \n",
    "    for v_cat in var_categoricas:\n",
    "        var_target = np.array(var_target)\n",
    "        var_values = np.array(datos[v_cat])\n",
    "        var_levels = np.unique(var_values)\n",
    "\n",
    "        mat_values = np.zeros(shape=(len(var_levels),2))\n",
    "\n",
    "        for i in range(len(var_target)):\n",
    "            # Obtención de la posición en los niveles del valor\n",
    "            for j in range(len(var_levels)):\n",
    "                if var_levels[j] == var_values[i]:\n",
    "                    pos = j\n",
    "                    break\n",
    "\n",
    "            # Estimación del número valores en cada nivel\n",
    "            if var_target[i]:\n",
    "                mat_values[pos][0] += 1\n",
    "            else:\n",
    "                mat_values[pos][1] += 1\n",
    "\n",
    "            # Obtención del IV\n",
    "            IV = 0\n",
    "            for j in range(len(var_levels)):\n",
    "                if mat_values[j][0] > 0 and mat_values[j][1] > 0:\n",
    "                    rt = mat_values[j][0] / (mat_values[j][0] + mat_values[j][1])\n",
    "                    rf = mat_values[j][1] / (mat_values[j][0] + mat_values[j][1])\n",
    "                    IV += (rt - rf) * np.log(rt / rf)        \n",
    "        # Se agrega el IV al listado\n",
    "        resultado.append(IV)\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b410b3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que calcula el VIF\n",
    "def calcularVIF(data):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    import pandas as pd\n",
    "    \n",
    "    features = list(data.columns)\n",
    "    num_features = len(features)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    \n",
    "    result = pd.DataFrame(index = ['VIF'], columns = features)\n",
    "    result = result.fillna(0)\n",
    "    \n",
    "    for ite in range(num_features):\n",
    "        x_features = features[:]\n",
    "        y_featue = features[ite]\n",
    "        x_features.remove(y_featue)\n",
    "        \n",
    "        x = data[x_features]\n",
    "        y = data[y_featue]\n",
    "        \n",
    "        model.fit(data[x_features], data[y_featue])\n",
    "        \n",
    "        result[y_featue] = 1/(1 - model.score(data[x_features], data[y_featue]))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7388f112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona las variables con VIF menor al máximo\n",
    "# Ejecuta el cáluculo del VIF de forma iterativa, eliminando una variable en cada iteración\n",
    "# hasta que todas las variables tengan un VIF por debajo del punto de corte\n",
    "def seleccionarPorVIF(data, max_VIF = 5):\n",
    "    import numpy as np\n",
    "    \n",
    "    result = data.copy(deep = True)\n",
    "    \n",
    "    VIF = calcularVIF(result)\n",
    "    \n",
    "    while VIF.values.max() > max_VIF:\n",
    "        col_max = np.where(VIF == VIF.values.max())[1][0]\n",
    "        features = list(result.columns)\n",
    "        features.remove(features[col_max])\n",
    "        result = result[features]\n",
    "        \n",
    "        VIF = calcularVIF(result)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb678d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features: Lista de nombres de columnas menos la target\n",
    "# x: Columnas menos la target\n",
    "# y: Target\n",
    "def StepWise(features, x, y):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    import matplotlib\n",
    "    from matplotlib import pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    # Modelo para realizar los ajustes\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Variable para almecena los índices de la lista de atributos usados\n",
    "    feature_order =  []\n",
    "    feature_error = []\n",
    "\n",
    "    # Iteración sobre todas las variables\n",
    "    for i in range(len(features)):\n",
    "        idx_try = [val for val in range(len(features)) if val not in feature_order]\n",
    "        iter_error = []\n",
    "\n",
    "        for i_try in idx_try:\n",
    "            useRow = feature_order[:]\n",
    "            useRow.append(i_try)\n",
    "\n",
    "            use = x[x.columns[useRow]]\n",
    "\n",
    "            model.fit(use, y)\n",
    "            rmsError = np.linalg.norm((y - model.predict(use)), 2)/np.sqrt(len(y))\n",
    "            iter_error.append(rmsError)\n",
    "\n",
    "        pos_best = np.argmin(iter_error)\n",
    "        feature_order.append(idx_try[pos_best])\n",
    "        feature_error.append(iter_error[pos_best])\n",
    "\n",
    "    for i in range(len(features)):\n",
    "        print(\"En el paso\", i, \"se ha insertado la variable\", \n",
    "              features[feature_order[i]], \"con un error\", feature_error[i])\n",
    "    \n",
    "    plt.plot(range(len(features)), feature_error, 'r-', label = 'Datos')\n",
    "    plt.xlabel('Numero de atributos')\n",
    "    plt.ylabel('Error (RMS)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
